#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass book
\use_default_options true
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Workflow
\end_layout

\begin_layout Standard
This section describes the workflow from a software perspective.
\end_layout

\begin_layout Itemize
Calibration
\end_layout

\begin_deeper
\begin_layout Itemize
Single-camera intrinsic calibration
\end_layout

\begin_layout Itemize
Stereo camera extrinsic calibration
\end_layout

\begin_layout Itemize
Projector calibration
\end_layout

\end_deeper
\begin_layout Itemize
Single-frame capture
\end_layout

\begin_deeper
\begin_layout Itemize
Capture binary patterns
\end_layout

\begin_layout Itemize
Capture sinusoid patterns
\end_layout

\begin_layout Itemize
Convert to 
\begin_inset Quotes eld
\end_inset

sheet
\begin_inset Quotes erd
\end_inset

 structure
\end_layout

\begin_layout Itemize
Use sheet information to compute surfel-sightings
\end_layout

\begin_layout Itemize
Correlate surfel-sightings into surfels
\end_layout

\end_deeper
\begin_layout Itemize
Orientation tracking
\end_layout

\begin_deeper
\begin_layout Itemize
Locate features in 3D using stereo camera
\end_layout

\begin_layout Itemize
Track feature movement in subsequent frames using 
\emph on
solvePnP
\end_layout

\end_deeper
\begin_layout Itemize
Export
\end_layout

\begin_deeper
\begin_layout Itemize
Heal surfel discrepancies
\end_layout

\begin_layout Itemize
Convert surfels to continuous surface
\end_layout

\begin_layout Itemize
Mesh surface to triangles
\end_layout

\begin_layout Itemize
Save to STL or OBJ
\end_layout

\end_deeper
\begin_layout Section
Calibration
\end_layout

\begin_layout Subsection
Intrinsic calibration
\end_layout

\begin_layout Standard

\emph on
Scan Studio
\emph default
 uses Zhang's method of calibration as implemented in OpenCV.
 This yields focal length for each camera/lens assembly.
\end_layout

\begin_layout Subsection
Extrinsic calibration
\end_layout

\begin_layout Standard
The images used for intrinsic calibration are re-used for extrinsic calibration.
 Image pairs are selected in which the calibration standard is fully visible
 in both frames, and the solvePnP algorithm is used to recover the relative
 orientation and position of the cameras.
\end_layout

\begin_layout Subsection
Projector calibration
\end_layout

\begin_layout Standard
The projector displays a sequence of horizontal and vertical patterns, combining
 Gray code and sinusoidal fringes.
 These patterns are projected onto a calibration standard.
 Since the position and orientation of the calibration standard can be calculate
d using only the camera information, it is possible to calculate the 3D
 location of each point on the standard as well as its 
\begin_inset Formula $\left(u_{p},v_{p}\right)$
\end_inset

 coordinates in projector space.
 This allows us, in effect, to temporarily regard the projector as a camera
 and use Zhang's method to calibrate.
\end_layout

\begin_layout Section
Single-frame capture
\end_layout

\begin_layout Subsection
Binary map capture
\end_layout

\begin_layout Standard
We projected Gray code onto the object to create a coarse mapping of projector-
\begin_inset Formula $u$
\end_inset

 to camera 
\begin_inset Formula $\left(u_{c},v_{c}\right)$
\end_inset

.
\end_layout

\begin_layout Subsection
Phase map capture
\end_layout

\begin_layout Standard
Binary mapping allows only for accuracy to the pixel level, creating a somewhat
 blocky appearance to the finished model.
 In addition, mismatching of the projector and camera resolution due to
 depth changes creates Moir√© patterns on the binary map, which introduces
 error.
\end_layout

\begin_layout Standard
To correct these issues, 
\emph on
Scan Studio
\emph default
 implements sinusoidal phase-shifting to capture information replacing the
 lower bits of the binary pattern.
 While the webcam input is quite noisy, the sinusoid algorithm need only
 resolve eight different values to provide pixel accuracy.
 Averaging multiple frames together and increasing the number of temporal
 shifts improves this accuracy to subpixel levels.
 These results are unwrapped using the binary map data.
\end_layout

\begin_layout Subsection
Convert to geometry
\end_layout

\begin_layout Standard
After the frames are captured, they are decoded as described above.
 Then, this decoded map is used along with triangulation algorithms described
 in chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Triangulation"

\end_inset

 (page 
\begin_inset CommandInset ref
LatexCommand pageref
reference "chap:Triangulation"

\end_inset

) to create a two-dimensional matrix of surface elements, or 
\emph on
surfels
\emph default
.
 The columns and rows of the matrix respectively represent 
\begin_inset Formula $u$
\end_inset

 and 
\begin_inset Formula $v$
\end_inset

 of the source image, allowing for correlation between adjacent surfels.
\end_layout

\begin_layout Standard
Normals are computed using weighted least-squares in the neighborhood of
 each point.
 The weights are calculated using a Gaussian function.
\end_layout

\begin_layout Standard
Colors are added to the sheet using the webcam's color input.
 The colors are corrected based on the angle between the projector ray and
 the surface normal so that it will have a uniform appearance on the final
 model.
\end_layout

\begin_layout Standard
The size of the surfel is calculated using the resolution of the camera
 and the distance from the camera to the surfel.
 This is not a hard geometric boundary, but rather a Gaussian distribution
 of where the surfel is likely to end.
\end_layout

\begin_layout Subsection
Surfel correlation
\end_layout

\begin_layout Standard
Surfels are recorrelated from scratch each time a frame is added.
 The surfels from each frame taken are pooled into a set and then merged
 depending on their proximity and similarity.
 Smaller surfels will supersede larger ones, meaning that the user can bring
 the subject closer to obtain higher resolution on a certain section.
\end_layout

\begin_layout Section
Orientation tracking
\end_layout

\begin_layout Subsection
Feature location
\end_layout

\begin_layout Standard

\emph on
Scan Studio
\emph default
 uses OpenCV's implementation of ORB feature identification.
 After the single-frame 3D capture is complete, the system takes a stereo-pair
 image from the cameras.
 The system then identifies features visible in both frames and correlates
 them according to their ORB descriptors.
 This allows the system to identify the 3D locations of these points, and
 it stores them along with their descriptors.
\end_layout

\end_body
\end_document
